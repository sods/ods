{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airline Delay Dataset\n",
    "=====================\n",
    "\n",
    "### [Neil D. Lawrence](http://inverseprobability.com), University of\n",
    "\n",
    "Cambridge\n",
    "\n",
    "### 2015-10-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "-----\n",
    "\n",
    "First we download some libraries and files to support the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mlai.py', <http.client.HTTPMessage at 0x10e870780>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/mlai.py','mlai.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('teaching_plots.py', <http.client.HTTPMessage at 0x10e870ba8>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/teaching_plots.py','teaching_plots.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gp_tutorial.py', <http.client.HTTPMessage at 0x10e870f98>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/gp_tutorial.py','gp_tutorial.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--setupplotcode{import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('paper')\n",
    "sns.set_palette('colorblind')}-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pods\n",
    "----\n",
    "\n",
    "In Sheffield we created a suite of software tools for ‘Open Data\n",
    "Science’. Open data science is an approach to sharing code, models and\n",
    "data that should make it easier for companies, health professionals and\n",
    "scientists to gain access to data science techniques.\n",
    "\n",
    "You can also check this blog post on [Open Data\n",
    "Science](http://inverseprobability.com/2014/07/01/open-data-science).\n",
    "\n",
    "The software can be installed using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/sods/ods\n",
      "  Cloning https://github.com/sods/ods to /private/var/folders/22/6ls22g994bdfdpwx4f9gcmsw0000gn/T/pip-req-build-77yekyf_\n",
      "  Running command git clone -q https://github.com/sods/ods /private/var/folders/22/6ls22g994bdfdpwx4f9gcmsw0000gn/T/pip-req-build-77yekyf_\n",
      "Building wheels for collected packages: pods\n",
      "  Building wheel for pods (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pods: filename=pods-0.0.21a0-py3-none-any.whl size=72694 sha256=f1bbe1e845164af083f5e78b55bce9b885c0e4cc5884a71dd7745c2c1fd80712\n",
      "  Stored in directory: /private/var/folders/22/6ls22g994bdfdpwx4f9gcmsw0000gn/T/pip-ephem-wheel-cache-5n8rrrz8/wheels/56/7f/87/0040ccbdd4956090a84a27ce7652170066c3ba2fc4078a892d\n",
      "Successfully built pods\n",
      "Installing collected packages: pods\n",
      "  Attempting uninstall: pods\n",
      "    Found existing installation: pods 0.0.21a0\n",
      "    Uninstalling pods-0.0.21a0:\n",
      "      Successfully uninstalled pods-0.0.21a0\n",
      "Successfully installed pods-0.0.21a0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade git+https://github.com/sods/ods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the command prompt where you can access your python installation.\n",
    "\n",
    "The code is also available on github:\n",
    "<a href=\"https://github.com/sods/ods\" class=\"uri\">https://github.com/sods/ods</a>\n",
    "\n",
    "Once `pods` is installed, it can be imported in the usual manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data on Airline Delays\n",
    "----------------------\n",
    "\n",
    "Flight arrival and departure times for every commercial flight in the\n",
    "USA from January 2008 to April 2008. This dataset contains extensive\n",
    "information about almost 2 million flights, including the delay (in\n",
    "minutes) in reaching the desitnation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.airline_delay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary contains the standard keys ‘X’ and ‘Y’, which\n",
    "contain 700,000 randomly sub-sampled training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape\n",
    "data['Y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally there are keys `Xtest` and `Ytest` which provide test data.\n",
    "The number of points considered to be *training data* is controlled by\n",
    "the argument `num_train` argument, which defaults to 700,000. This\n",
    "number is chosen as it matches that used in the Gaussian Processes for\n",
    "Big Data paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Xtest'].shape\n",
    "data['Ytest'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was compiled by Nicolò Fusi for the paper Hensman et al.\n",
    "(n.d.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Processes for Big Data (In UAI'13). J. Hensman, N. Fusi and N. D. Lawrence\n"
     ]
    }
   ],
   "source": [
    "print(data['citation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And extra information about the data is included, as standard, under the\n",
    "keys `info` and `details`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline delay data used for demonstrating Gaussian processes for big data.\n",
      "\n",
      "Flight arrival and departure times for every commercial flight in the USA from January 2008 to April 2008. This dataset contains extensive information about almost 2 million flights, including the delay (in minutes) in reaching the destination.\n"
     ]
    }
   ],
   "source": [
    "print(data['info'])\n",
    "print()\n",
    "print(data['details'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hensman, J., Fusi, N., Lawrence, N.D., n.d. Gaussian processes for big\n",
    "data, in:."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
