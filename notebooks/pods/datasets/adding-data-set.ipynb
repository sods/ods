{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a Data Set to `pods`\n",
    "\n",
    "### 2014-05-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->\n",
    "\n",
    "Adding a data set to GPy should be done in two stages. Firstly, you need\n",
    "to edit the `data_resources.json` file to provide information about\n",
    "where to download the data from and what the license and citation\n",
    "information for the data is. Then you can edit the `datasets.py` file,\n",
    "located in `GPy.util` to load in the data and perform any preprocessing,\n",
    "before returning the data set to the user in the standard dictionary\n",
    "format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Editing `data_resources.json`\n",
    "\n",
    "A `json` file is a simple way of storing a python dictionary in a format\n",
    "that is interchangeable with other languages. This file is loaded in at\n",
    "the beginning of `datasets.py` to provide information on where he data\n",
    "set is located, what its licensing terms are and any other standard\n",
    "details about the data. You can use any `json` editor to edit the file.\n",
    "You can also use a standard text editor, but be careful not to damage\n",
    "the format of the file! If you do damage the format, there are various\n",
    "on line json format checkers you can use to try and recover the file.\n",
    "\n",
    "The file consists of a comma separated list of dictionary entries. Each\n",
    "dictionary entry corresponds to a single data set. Below is the\n",
    "dictionary entry for the Boston Housing data.\n",
    "\n",
    "    \"boston_housing\": {\n",
    "        \"citation\": \"Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.\",\n",
    "        \"details\": \"The Boston Housing data relates house values in Boston to a range of input variables.\",\n",
    "        \"files\": [\n",
    "            [\n",
    "                \"Index\",\n",
    "                \"housing.data\",\n",
    "                \"housing.names\"\n",
    "            ]\n",
    "        ],\n",
    "        \"license\": null,\n",
    "        \"size\": 51276,\n",
    "        \"urls\": [\n",
    "            \"http://archive.ics.uci.edu/ml/machine-learning-databases/housing/\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "The entry includes firstly, the data set name. Then it includes six\n",
    "fields for describing. \\* `url` The download url location of the data.\n",
    "This is provided as a *list* of urls. Just in case several different\n",
    "locations need to be visited. Here the list contains only one element.\n",
    "\\* `files` This is a *list of lists*. Each list contains the files to be\n",
    "downloaded from the corresponding url. Here there are three files\n",
    "required from the first (and only) url. \\* `details` Some helpful\n",
    "information for the user about the data. \\* `citation` The citation to\n",
    "use when publishing on the data. If you use a data set you should always\n",
    "cite its origin. \\* `size` A total size information for the user to know\n",
    "how much disk space the data will take when its all downloaded. \\*\n",
    "`license` The license terms for the data. Many data sets have a license\n",
    "associated. Don’t include data sets in this collection that don’t permit\n",
    "their inclusion. There don’t appear to be any license constraints for\n",
    "the use of the Boston housing data, so in this case this vealue is set\n",
    "to `null`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Including the Data in `datasets.py`\n",
    "\n",
    "The `data_resources.json` file includes all the information about how to\n",
    "download the data. Now in `datasets.py` we write a short dataset\n",
    "recovery function to execute the download and return the data to the\n",
    "user. It has the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boston_housing(data_set='boston_housing'):\n",
    "    if not data_available(data_set):\n",
    "        download_data(data_set)\n",
    "    all_data = np.genfromtxt(os.path.join(data_path, data_set, 'housing.data'))\n",
    "    X = all_data[:, 0:13]\n",
    "    Y = all_data[:, 13:14]\n",
    "    return data_details_return({'X' : X, 'Y': Y}, data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function name allows users to call\n",
    "`data = pods.datasets.boston_housing()` to acquire the data. You should\n",
    "use a name that makes it clear to readers of the code what is going on.\n",
    "The data set name is passed to the function as a default argument. This\n",
    "name corresponds to the entry in the `json` file.\n",
    "\n",
    "The next two lines call the function `data_available()` to check if the\n",
    "data set is already in the cache. If the data set is not there, then\n",
    "`download_data()`, which handles the interface with the user for\n",
    "downloading the data is called.\n",
    "\n",
    "The location of the cached data can be determined through the\n",
    "configuration file. By default it is set to be in a temporary directory\n",
    "under your home directory: `tmp/GPy-datasets`. But you can change this\n",
    "by creating your own configuration file in your home directiory,\n",
    "`.gpy_user.cfg` or by editing the configuration file for your GPy\n",
    "installation, `installation.cfg`. See [this\n",
    "notebook](../pods/config.ipynb) for details on the config file.\n",
    "\n",
    "The final line, `data_details_return` returns the dictionary of\n",
    "information loaded in from `data_resource.json` alongside the dictionary\n",
    "we’ve just constructed. The dictionary we return to the user is in a\n",
    "standard format with entries `X` and `Y` for the covariates and response\n",
    "variables.\n",
    "\n",
    "Now things should be ready for you to download the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods\n",
    "data = pods.datasets.boston_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Step 3: Preprocessing\n",
    "\n",
    "In the above we haven’t performed any preprocessing of the data. What if\n",
    "we want to preprocess the data before giving it to the user? We can\n",
    "write a different, additional, version of the data set recovery function\n",
    "for providing a different preprocessing. Here we preprocess the `Y`\n",
    "values to be zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pods.datasets import *\n",
    "import numpy as np\n",
    "def boston_housing_preprocess(data_set='boston_housing'):\n",
    "    if not data_available(data_set):\n",
    "        download_data(data_set)\n",
    "    all_data = np.genfromtxt(os.path.join(data_path, data_set, 'housing.data'))\n",
    "    X = all_data[:, 0:13]\n",
    "    Y = all_data[:, 13:14]\n",
    "    Y = (Y - np.mean(Y))/np.std(Y)\n",
    "    return data_details_return({'X' : X, 'Y': Y, \n",
    "                                'info' : 'The response variables have been preprocessed to have zero mean and unit standard deviation'\n",
    "                                }, data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access the same data set, but this time, because we have the\n",
    "data in cache no download is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston_housing_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this version of the data set we can check that the response\n",
    "variables have been normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean: ', data['Y'].mean())\n",
    "print('Standard deviation ', data['Y'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
